{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the dataset from the below link\n",
    "https://www.kaggle.com/arbethi/wild-animal-detection-and-alerting-system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import ImageDataGenerator Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import ImageDataGenerator Library\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#Define the parameters /arguments for ImageDataGenerator class\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,\n",
    "        rotation_range=90,zoom_range=0.2,horizontal_flip=True)\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying ImageDataGenerator functionality to trainset and testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 993 images belonging to 3 classes.\n",
      "Found 353 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "#Applying ImageDataGenerator functionality to trainset\n",
    "x_train=train_datagen.flow_from_directory(\n",
    "    directory= r\"C:\\Users\\Manasa\\Desktop\\project\\Intelligent-alert-system-for-forest-tribal-people-main\\Dataset\\train_set\",\n",
    "    target_size=(128,128),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical')\n",
    "\n",
    "#Applying ImageDataGenerator functionality to test set\n",
    "x_test=test_datagen.flow_from_directory(\n",
    "    directory= r\"C:\\Users\\Manasa\\Desktop\\project\\Intelligent-alert-system-for-forest-tribal-people-main\\Dataset\\test_set\",\n",
    "    target_size=(128,128),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the model building libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Importing the model building libraries'''\n",
    "#to define linear initializations import Sequential\n",
    "from tensorflow.keras.models import Sequential\n",
    "#To add layers import Dense\n",
    "from tensorflow.keras.layers import Dense\n",
    "# to create a convolution kernel import Convolution2D\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "# Adding Max pooling Layer\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "# Adding Flatten Layer\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding CNN layers\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(128,128,3),\n",
    "                        activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Max pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Max pooling Layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Flatten Layer\n",
    "model.add(Flatten()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Hidden Layers\n",
    "model.add(Dense(kernel_initializer='uniform',activation='relu',units=300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 2nd hidden layer\n",
    "model.add(Dense(kernel_initializer='uniform',activation='relu',units=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 3rd hidden layer\n",
    "model.add(Dense(kernel_initializer='uniform',activation='relu',units=60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding output layer\n",
    "model.add(Dense(kernel_initializer='uniform',activation='softmax',units=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the learning process or compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the learning process\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 127008)            0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 300)               38102700  \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 183       \n",
      "=================================================================\n",
      "Total params: 38,139,939\n",
      "Trainable params: 38,139,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Domestic': 0, 'Human': 1, 'Wild': 2}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "31/31 [==============================] - 13s 412ms/step - loss: 0.7546 - accuracy: 0.6633 - val_loss: 0.8812 - val_accuracy: 0.6420\n",
      "Epoch 2/20\n",
      "31/31 [==============================] - 13s 419ms/step - loss: 0.7534 - accuracy: 0.6431 - val_loss: 0.9247 - val_accuracy: 0.5776\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 13s 409ms/step - loss: 0.7337 - accuracy: 0.6466 - val_loss: 0.9441 - val_accuracy: 0.5511\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 12s 401ms/step - loss: 0.7553 - accuracy: 0.6552 - val_loss: 0.7076 - val_accuracy: 0.6584\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 12s 393ms/step - loss: 0.7109 - accuracy: 0.6757 - val_loss: 1.1169 - val_accuracy: 0.5852\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 12s 401ms/step - loss: 0.7334 - accuracy: 0.6714 - val_loss: 0.8474 - val_accuracy: 0.6646\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 13s 415ms/step - loss: 0.6826 - accuracy: 0.7089 - val_loss: 0.6654 - val_accuracy: 0.7102\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 13s 407ms/step - loss: 0.7155 - accuracy: 0.6895 - val_loss: 0.9535 - val_accuracy: 0.6460\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 12s 399ms/step - loss: 0.6552 - accuracy: 0.6923 - val_loss: 0.8314 - val_accuracy: 0.6477\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 13s 407ms/step - loss: 0.6960 - accuracy: 0.6915 - val_loss: 1.0357 - val_accuracy: 0.5839\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 13s 430ms/step - loss: 0.6156 - accuracy: 0.7380 - val_loss: 1.0226 - val_accuracy: 0.6477\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 12s 403ms/step - loss: 0.7035 - accuracy: 0.6935 - val_loss: 0.9776 - val_accuracy: 0.5652\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 13s 404ms/step - loss: 0.7393 - accuracy: 0.6632 - val_loss: 0.8295 - val_accuracy: 0.6420\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 12s 405ms/step - loss: 0.6812 - accuracy: 0.7016 - val_loss: 1.1941 - val_accuracy: 0.5280\n",
      "Epoch 15/20\n",
      "31/31 [==============================] - 12s 399ms/step - loss: 0.6141 - accuracy: 0.7193 - val_loss: 1.0559 - val_accuracy: 0.6591\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 13s 411ms/step - loss: 0.6501 - accuracy: 0.7077 - val_loss: 0.7229 - val_accuracy: 0.6708\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 13s 423ms/step - loss: 0.6246 - accuracy: 0.7173 - val_loss: 1.2252 - val_accuracy: 0.5966\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 12s 403ms/step - loss: 0.6416 - accuracy: 0.7157 - val_loss: 1.1461 - val_accuracy: 0.5404\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 13s 406ms/step - loss: 0.6758 - accuracy: 0.6881 - val_loss: 0.6984 - val_accuracy: 0.6761\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 13s 426ms/step - loss: 0.5844 - accuracy: 0.7440 - val_loss: 0.9133 - val_accuracy: 0.6273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a31897fd90>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(x_train,steps_per_epoch=993//32,\n",
    "                    epochs=20,\n",
    "                    validation_data=x_test,\n",
    "                    validation_steps=353//32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model \n",
    "model.save('alert.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Domestic': 0, 'Human': 1, 'Wild': 2}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random image prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#import numpy library\n",
    "import numpy as np\n",
    "#import load_model method to load our saved model\n",
    "from keras.models import load_model\n",
    "#import image from keras.preprocessing\n",
    "from keras.preprocessing import image\n",
    "#loading our saved model file\n",
    "model = load_model(\"alert.h5\")\n",
    "img = image.load_img(r\"../Dataset/test_set/Domestic/domestic (20).jpg\",\n",
    "                     target_size=(128,128))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "#expanding the shape of image to 4 dimensions\n",
    "x = np.expand_dims(x,axis=0)\n",
    "pred = np.argmax(model.predict(x))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video streaming and alerting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-afc4cf470d2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     cv2.putText(frame, \"predicted  class = \"+str(name[p]), (100,100), \n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "#import opencv\n",
    "import cv2\n",
    "#import numpy\n",
    "import numpy as np\n",
    "from keras.preprocessing import image \n",
    "from keras.models  import load_model\n",
    "#import Client from twilio API\n",
    "from twilio.rest import Client\n",
    "#import playsound package\n",
    "from playsound import playsound\n",
    "\n",
    "#Load saved model file using load_model method\n",
    "model = load_model('alert.h5')\n",
    "#To read webcam\n",
    "video = cv2.VideoCapture(0)\n",
    "#Type of classes or names of the labels that we considered\n",
    "name = ['Human','Domestic', 'Wild']\n",
    "#To execute the program repeatedly using while loop   \n",
    "while(1):\n",
    "    success, frame = video.read()\n",
    "    cv2.imwrite(\"image.jpg\",frame)\n",
    "    img = image.load_img(\"image.jpg\",target_size = (128,128))\n",
    "    x  = image.img_to_array(img)\n",
    "    x = np.expand_dims(x,axis = 0)\n",
    "    pred = np.argmax(model.predict(x))\n",
    "    p = pred[0][0]\n",
    "    print(pred)\n",
    "    cv2.putText(frame, \"predicted  class = \"+str(name[p]), (100,100), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1)\n",
    "    \n",
    "    pred = model.predict_classes(x)\n",
    "    if pred[0]==2:\n",
    "        #twilio account ssid\n",
    "        account_sid = 'AC7031a31cfcc98cf64e0eef7d283434a8'\n",
    "        #twilo account authentication toke\n",
    "        auth_token = '84df78b8573a5fede90d9b8217dde66f'\n",
    "        client = Client(account_sid, auth_token)\n",
    "\n",
    "        message = client.messages \\\n",
    "        .create(\n",
    "         body='Danger!. Wild animal is detected, stay alert',\n",
    "         from_='+16468467615', #the free number of twilio\n",
    "         to='+916301692688') #enter your number here\n",
    "        print(message.sid)\n",
    "        print('Danger!!')\n",
    "        print('Animal Detected')\n",
    "        print ('SMS sent!')\n",
    "        #playsound(r'C:\\Users\\DELL\\Downloads\\Tornado_Siren_II-Delilah-0.mp3')\n",
    "        #break\n",
    "    else:\n",
    "        print(\"No Danger\")\n",
    "       #break\n",
    "    cv2.imshow(\"image\",frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('a'): \n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "#import facevec\n",
    "import numpy as np\n",
    "from keras.preprocessing import image \n",
    "from keras.models  import load_model\n",
    "\n",
    "model = load_model('alert.h5') \n",
    "video = cv2.VideoCapture(0)\n",
    "name = [\"Human\",\"Wild aniaml\",\"otimher\"]\n",
    "    \n",
    "while(1):\n",
    "    success, frame = video.read()\n",
    "    cv2.imwrite(\"image.jpg\",frame)\n",
    "    img = image.load_img(\"image.jpg\",target_size = (64,64))\n",
    "    x  = image.img_to_array(img)\n",
    "    x = np.expand_dims(x,axis = 0)\n",
    "    pred = model.predict_classes(x)\n",
    "    p = pred[0]\n",
    "    print(pred)\n",
    "    cv2.putText(frame, \"predicted  class = \"+str(name[p]), (100,100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1)\n",
    "    cv2.imshow(\"image\",frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('a'): \n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
